{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, fnmatch\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import random\n",
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    "# find all files, output names\n",
    "def findFastqFiles(directory, pattern):\n",
    "    \"\"\"Walks the directory structure, appending filenames to an array\"\"\"\n",
    "    filenames = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for basename in files:\n",
    "            if fnmatch.fnmatch(basename, pattern):\n",
    "                filename = os.path.join(root, basename)\n",
    "                filenames.append(filename)\n",
    "    return filenames\n",
    "\n",
    "# parse sequences, output percent\n",
    "def parseFastqSeq(array):\n",
    "    \"\"\"Returns percent of sequences greater than 30\"\"\"\n",
    "    all_sequences   = []\n",
    "    large_sequences = []\n",
    "    for filename in array:\n",
    "        for sequence in SeqIO.parse(open(filename, \"r\"), \"fastq\"):\n",
    "            if len(sequence.seq) > 30:\n",
    "                large_sequences.append(sequence)\n",
    "            all_sequences.append(sequence)\n",
    "    percent = len(large_sequences) / float(len(all_sequences))\n",
    "    return percent\n",
    "\n",
    "def freqFastaSeq(file):\n",
    "    \"\"\"Parses a fasta/q file, returns 10 most common sequences\"\"\"\n",
    "    sequences = []\n",
    "    fasta_sequences = SeqIO.parse(open(file),'fastq')\n",
    "    for fasta in fasta_sequences:\n",
    "        sequences.append(str(fasta))\n",
    "    from collections import Counter\n",
    "    c = Counter(sequences)\n",
    "    most_common_seq = c.most_common(10)\n",
    "    return most_common_seq\n",
    "\n",
    "def parse_fastq(filename, suffix):\n",
    "    # output the file to a dictionary\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "    head = [item[:-1] for item in lines[0::4]]\n",
    "    read = [item[:-1] for item in lines[1::4]]\n",
    "    qual = [item[:-1] for item in lines[3::4]]\n",
    "    return {'Header_'+str(suffix): head, 'Sequence_'+str(suffix): read, 'QScore_'+str(suffix): qual}\n",
    "\n",
    "def constrained_sum_sample_pos(n, total):\n",
    "    \"\"\"Return a randomly chosen list of n positive integers summing to total.\n",
    "    Each such list is equally likely to occur.\"\"\"\n",
    "\n",
    "    dividers = sorted(random.sample(xrange(1, total), n - 1))\n",
    "    return [a - b for a, b in zip(dividers + [total], [0] + dividers)]\n",
    "\n",
    "def gen_qscore(length, score):\n",
    "    \"\"\"Return a qscore of length length\"\"\"\n",
    "    myScore = constrained_sum_sample_pos(length,score)\n",
    "    return ''.join([chr(i+33) for i in myScore])\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def merge_dicts(*dict_args):\n",
    "    '''\n",
    "    Given any number of dicts, shallow copy and merge into a new dict,\n",
    "    precedence goes to key value pairs in latter dicts.\n",
    "    '''\n",
    "    result = {}\n",
    "    for dictionary in dict_args:\n",
    "        result.update(dictionary)\n",
    "    return result\n",
    "\n",
    "def return_reverse_complement(seq):\n",
    "    # returns the reverse complement of a sequence\n",
    "    seq1 = 'ATCGNTAGCNatcgntagcn'\n",
    "    seq_dict = {seq1[i]: seq1[i + 5]\n",
    "                for i in range(18) if i < 5 or 9 <= i < 13}\n",
    "    return \"\".join([seq_dict[base] for base in reversed(seq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import difflib\n",
    "\n",
    "def parse_fastq(filename, suffix):\n",
    "    # output the file to a dictionary\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "    head = [item[:-1] for item in lines[0::4]]\n",
    "    read = [item[:-1] for item in lines[1::4]]\n",
    "    qual = [item[:-1] for item in lines[3::4]]\n",
    "    return {'Header_'+str(suffix): head, 'Sequence_'+str(suffix): read, 'QScore_'+str(suffix): qual}\n",
    "\n",
    "# locate the files we want to work with\n",
    "# mac\n",
    "sdDevelop_R1 = \"/Users/ChrisM/Documents/workspace/iBest/testingSD/sdDevelop/no_dup_R1.fastq\"\n",
    "sdDevelop_R2 = \"/Users/ChrisM/Documents/workspace/iBest/testingSD/sdDevelop/no_dup_R2.fastq\"\n",
    "\n",
    "sdMaster_R1 = \"/Users/ChrisM/Documents/workspace/iBest/testingSD/sdMaster/output_nodup_PE1.fastq\"\n",
    "sdMaster_R2 = \"/Users/ChrisM/Documents/workspace/iBest/testingSD/sdMaster/output_nodup_PE2.fastq\"\n",
    "\n",
    "rawReads_R1 = \"/Users/ChrisM/Documents/workspace/iBest/testingSD/rawReads/tiny_R1.fastq\"\n",
    "rawReads_R2 = \"/Users/ChrisM/Documents/workspace/iBest/testingSD/rawReads/tiny_R2.fastq\"\n",
    "\n",
    "# create an index of the files -- index is faster and less RAM intense\n",
    "sdDevelopR1 = parse_fastq(sdDevelop_R1, \"R1\")\n",
    "sdDevelopR2 = parse_fastq(sdDevelop_R2, \"R2\")\n",
    "\n",
    "sdMasterR1 = parse_fastq(sdMaster_R1, \"R1\")\n",
    "sdMasterR2 = parse_fastq(sdMaster_R2, \"R2\")\n",
    "\n",
    "rawReadsR1 = parse_fastq(rawReads_R1, \"R1\")\n",
    "rawReadsR2 = parse_fastq(rawReads_R2, \"R2\")\n",
    "rawReads = merge_dicts(rawReadsR1, rawReadsR2)\n",
    "   \n",
    "raw_df = pd.DataFrame.from_dict(rawReads)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# develop removes less than master so let's find out the difference\n",
    "# what did sdDevelop remove from rawReads\n",
    "diffDev = [i for i in rawReadsR1['Header_R1'] if i not in sdDevelopR1['Header_R1']]\n",
    "\n",
    "# what did sdMaster remove from rawReads\n",
    "diffMaster = [i for i in rawReadsR1['Header_R1'] if i not in sdMasterR1['Header_R1']]\n",
    "        \n",
    "# this is what sdMaster removes that sdDevelop does not\n",
    "diffRemoved = [i for i in diffMaster if i not in diffDev]\n",
    "\n",
    "# this is all of the headers\n",
    "allHeaders = [i for i in rawReadsR1['Header_R1']]\n",
    "\n",
    "print(\"done\")\n",
    "print(len(diffMaster))\n",
    "print(len(diffDev))\n",
    "print(len(diffRemoved))\n",
    "print(len(allHeaders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now we can find out why\n",
    "# test if it's the reverse complement\n",
    "# assumes s = 10 and l = 10\n",
    "# find duplicates of diffRemoved\n",
    "myRCKeys = []\n",
    "s = 10\n",
    "l = s + 10\n",
    "for arow, acol in raw_df.iterrows(): # raw_df is a dataframe of the truncated raw reads\n",
    "    if acol['Header_R1'] in diffRemoved: # diffRemoved is the difference between Master and Develop\n",
    "        a_r1 = acol['Sequence_R1'] # r1 of the removed duplicate\n",
    "        a_r2 = acol['Sequence_R2'] # r2 of the removed duplicate\n",
    "        for brow, bcol in raw_df.iterrows(): # now we are looking for what was kept\n",
    "            b_r1 = bcol['Sequence_R1'] # r1 to compare to\n",
    "            b_r2 = bcol['Sequence_R2'] # r2 to compare to\n",
    "            for j in range(len(a_r1)-l): # python is zero indexed and don't want to include EOL\n",
    "                if a_r1[j+s:j+l] + a_r2[j+s:j+l] == b_r1[j+s:j+l] + b_r2[j+s:j+l]: # from Sam's code\n",
    "                    if bcol['Header_R1'] not in myRCKeys: # keeping track of what gets flagged\n",
    "                        myRCKeys.append(bcol['Header_R1'])\n",
    "                                    \n",
    "print(\"done\")  \n",
    "print(len(myRCKeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find duplicates of diffDev\n",
    "myDevKeys = []\n",
    "s = 10\n",
    "l = s + 10\n",
    "for arow, acol in raw_df.iterrows(): # raw_df is a dataframe of the truncated raw reads\n",
    "    if acol['Header_R1'] in diffDev: # diffDev is the difference between raw and Develop\n",
    "        a_r1 = acol['Sequence_R1'] # r1 of the removed duplicate\n",
    "        a_r2 = acol['Sequence_R2'] # r2 of the removed duplicate\n",
    "        for brow, bcol in raw_df.iterrows(): # now we are looking for what was kept\n",
    "            b_r1 = bcol['Sequence_R1'] # r1 to compare to\n",
    "            b_r2 = bcol['Sequence_R2'] # r2 to compare to\n",
    "            for j in range(len(a_r1)-(s+l)): # python is zero indexed and don't want to include EOL\n",
    "                if a_r1[j+s:j+l] + a_r2[j+s:j+l] == b_r1[j+s:j+l] + b_r2[j+s:j+l]: # from Sam's code\n",
    "                    if bcol['Header_R1'] not in myDevKeys: # keeping track of what gets flagged\n",
    "                        myDevKeys.append(bcol['Header_R1'])\n",
    "                                    \n",
    "print(\"done\")  \n",
    "print(len(myDevKeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find duplicates of diffMaster\n",
    "myMstrKeys = []\n",
    "s = 10\n",
    "l = s + 10\n",
    "for arow, acol in raw_df.iterrows(): # raw_df is a dataframe of the truncated raw reads\n",
    "    if acol['Header_R1'] in diffMaster: # diffDev is the difference between raw and Develop\n",
    "        a_r1 = acol['Sequence_R1'] # r1 of the removed duplicate\n",
    "        a_r2 = acol['Sequence_R2'] # r2 of the removed duplicate\n",
    "        for brow, bcol in raw_df.iterrows(): # now we are looking for what was kept\n",
    "            b_r1 = bcol['Sequence_R1'] # r1 to compare to\n",
    "            b_r2 = bcol['Sequence_R2'] # r2 to compare to\n",
    "            for j in range(len(a_r1)-(s+l)): # python is zero indexed and don't want to include EOL\n",
    "                if a_r1[j+s:j+l] + a_r2[j+s:j+l] == b_r1[j+s:j+l] + b_r2[j+s:j+l]: # from Sam's code\n",
    "                    if bcol['Header_R1'] not in myMstrKeys: # keeping track of what gets flagged\n",
    "                        myMstrKeys.append(bcol['Header_R1'])\n",
    "                                    \n",
    "print(\"done\")  \n",
    "print(len(myMstrKeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for arow, acol in raw_df.iterrows():\n",
    "    if acol['Header_R1'] in diffRemoved:    \n",
    "        print(acol['Header_R1'])\n",
    "        print(acol['Sequence_R1'])\n",
    "        print(\"+\")\n",
    "        print(acol['QScore_R1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for arow, acol in raw_df.iterrows():\n",
    "    if acol['Header_R1'] in myRCKeys:      \n",
    "        print(acol['Header_R2'])\n",
    "        print(acol['Sequence_R2'])\n",
    "        print(\"+\")\n",
    "        print(acol['QScore_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for arow, acol in raw_df.iterrows():\n",
    "    if acol['Header_R1'] in diffDev:    \n",
    "        print(acol['Header_R1'])\n",
    "        print(acol['Sequence_R1'])\n",
    "        print(\"+\")\n",
    "        print(acol['QScore_R1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for arow, acol in raw_df.iterrows():\n",
    "    if acol['Header_R1'] in myDevKeys:      \n",
    "        print(acol['Header_R2'])\n",
    "        print(acol['Sequence_R2'])\n",
    "        print(\"+\")\n",
    "        print(acol['QScore_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    "def merge_dicts(*dict_args):\n",
    "    '''\n",
    "    Given any number of dicts, shallow copy and merge into a new dict,\n",
    "    precedence goes to key value pairs in latter dicts.\n",
    "    '''\n",
    "    result = {}\n",
    "    for dictionary in dict_args:\n",
    "        result.update(dictionary)\n",
    "    return result\n",
    "\n",
    "def parse_fastq(filename, suffix):\n",
    "    # output the file to a dictionary\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "    head = [item[:-1] for item in lines[0::4]]\n",
    "    read = [item[:-1] for item in lines[1::4]]\n",
    "    qual = [item[:-1] for item in lines[3::4]]\n",
    "    return {'Header_'+str(suffix): head, 'Sequence_'+str(suffix): read, 'QScore_'+str(suffix): qual}\n",
    "\n",
    "# just want to find the duplicates of these headers\n",
    "\n",
    "myHeaders = [\"@M03610:8:000000000-AJJAD:1:1111:25298:9039 1:N:0:20\",\n",
    "            \"@M03610:8:000000000-AJJAD:1:2114:19128:4795 1:N:0:20\",\n",
    "            \"@M03610:8:000000000-AJJAD:1:1114:8658:23919 1:N:0:20\"]\n",
    "\n",
    "# these are the rawreads files\n",
    "#rawReads_R1 = \"/Users/ChrisM/Documents/workspace/iBest/testingSD/rawReads/15-03190-2_S20_L001_R1_001.fastq\"\n",
    "#rawReads_R2 = \"/Users/ChrisM/Documents/workspace/iBest/testingSD/rawReads/15-03190-2_S20_L001_R2_001.fastq\"\n",
    "rawReads_R1 = \"C:/cygwin64/home/chrism/workspace/testingSD/rawReads/15-03190-2_S20_L001_R1_001.fastq\"\n",
    "rawReads_R2 = \"C:/cygwin64/home/chrism/workspace/testingSD/rawReads/15-03190-2_S20_L001_R2_001.fastq\"\n",
    "\n",
    "# gather the headers into a dataframe to make searching easier\n",
    "rawReadsR1 = parse_fastq(rawReads_R1, \"R1\")\n",
    "rawReadsR2 = parse_fastq(rawReads_R2, \"R2\")\n",
    "rawReads = merge_dicts(rawReadsR1, rawReadsR2)\n",
    "raw_df = pd.DataFrame.from_dict(rawReads)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find duplicates of myHeaders\n",
    "myMstrKeys = []\n",
    "s = 10\n",
    "l = s + 10\n",
    "for arow, acol in raw_df.iterrows(): # raw_df is a dataframe of the truncated raw reads\n",
    "    if acol['Header_R1'] in myHeaders: # difference between raw and myHeaders\n",
    "        a_r1 = acol['Sequence_R1'] # r1 of the removed duplicate\n",
    "        a_r2 = acol['Sequence_R2'] # r2 of the removed duplicate\n",
    "        for brow, bcol in raw_df.iterrows(): # now we are looking for what was kept\n",
    "            if bcol['Header_R1'] not in myHeaders: # difference between raw and myHeaders\n",
    "                b_r1 = bcol['Sequence_R1'] # r1 to compare to\n",
    "                b_r2 = bcol['Sequence_R2'] # r2 to compare to\n",
    "                for j in range(len(a_r1)-(s+l)): # python is zero indexed and don't want to include EOL\n",
    "                    if a_r1[j+s:j+l] + a_r2[j+s:j+l] == b_r1[j+s:j+l] + b_r2[j+s:j+l]: \n",
    "                        if bcol['Header_R1'] not in myMstrKeys: # keeping track of what gets flagged\n",
    "                            myMstrKeys.append(bcol['Header_R1'])\n",
    "                    elif a_r1[j+s:j+l] + a_r2[j+s:j+l] == b_r2[j+s:j+l] + b_r1[j+s:j+l]: \n",
    "                        if bcol['Header_R1'] not in myMstrKeys: # keeping track of what gets flagged\n",
    "                            myMstrKeys.append(bcol['Header_R1'])\n",
    "                                    \n",
    "print(\"done\")  \n",
    "print(len(myMstrKeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myDevKeys = ['@M03610:8:000000000-AJJAD:1:1111:25298:9039 1:N:0:20',\n",
    "            '@M03610:8:000000000-AJJAD:1:2114:19128:4795 1:N:0:20',\n",
    "            '@M03610:8:000000000-AJJAD:1:1114:8658:23919 1:N:0:20',\n",
    "            '@M03610:8:000000000-AJJAD:1:1112:17531:6370 1:N:0:20',\n",
    "            '@M03610:8:000000000-AJJAD:1:2113:8433:13563 1:N:0:20',\n",
    "            '@M03610:8:000000000-AJJAD:1:2112:10461:22345 1:N:0:20']\n",
    "\n",
    "for arow, acol in raw_df.iterrows():\n",
    "    if acol['Header_R1'] in myDevKeys:      \n",
    "        print(acol['Header_R1'])\n",
    "        print(acol['Sequence_R1'])\n",
    "        print(\"+\")\n",
    "        print(acol['QScore_R1'])\n",
    "        \n",
    "print(\"________________________________________\")\n",
    "\n",
    "for arow, acol in raw_df.iterrows():\n",
    "    if acol['Header_R1'] in myDevKeys:      \n",
    "        print(acol['Header_R2'])\n",
    "        print(acol['Sequence_R2'])\n",
    "        print(\"+\")\n",
    "        print(acol['QScore_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
